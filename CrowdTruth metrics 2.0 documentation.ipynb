{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let:\n",
    "\n",
    "* $workers(s):$ all workers that annotate sentence $s$;\n",
    "* $sentences(i):$ all sentences annotated by worker $i$;\n",
    "* $WorkVec(i, s):$ annotations of worker $i$ on sentence $s$ as a binary vector;\n",
    "* $SentVec(s) = \\sum_{i \\in workers(s)} WorkVec(i,s)$, where $s$ is a sentence.\n",
    "\n",
    "## Sentence Quality Score (SQS)\n",
    "\n",
    "The sentence quality score $SQS(s)$ is computed as the average cosine similarity between all worker vectors for a given sentence $s$, weighted by the worker quality ($WQS$) and relation quality ($RQS$). The goal is to capture the degree of agreement in annotating the sentence. Through the weighted average, workers and relations with lower quality will have less of an impact on the final score.\n",
    "\n",
    "$$ SQS(s) = \\frac{\\sum_{i, j \\in workers(s)} Wcos(WorkVec(i,s), WorkVec(j,s)) \\; WQS(i) \\; WQS(j)}{\\sum_{i, j \\in workers(s)} WQS(i) \\; WQS(j)}, \\; i \\neq j.$$\n",
    "\n",
    "\n",
    "### Weighted Cosine\n",
    "\n",
    "To weigh the metrics with the relation quality, we compute $Wcos$, the weighted version of the cosine similarity. This metric is only applicable to closed tasks, where relation quality can be calculated across sentences. For open-ended tasks, we consider relation quality equal to 1 and calculate the regular cosine similarity.\n",
    "\n",
    "$$ Wcos(vec_1, vec_2) = \\frac{\\sum_{r} vec_1(r) \\; vec_2(r) \\; RQS(r)}{\\sqrt{(\\sum_{r} vec_1^2(r) \\; RQS(r)) \\; (\\sum_{r} vec_2^2(r) \\; RQS(r))}} .$$ \n",
    "\n",
    "\n",
    "## Worker Quality Score (WQS)\n",
    "\n",
    "The worker quality score $WQS(i)$ for a given worker $i$ is the product of 2 separate metrics - the worker-worker agreement $WWA(i)$ and the worker-sentence agreement $WSA(i)$.\n",
    "\n",
    "$$ WQS(i) = WSA(i) \\; WWA(i) .$$\n",
    "\n",
    "### Worker-Sentence Agreement\n",
    "\n",
    "The worker-sentence agreement $WSA(i)$ is the average cosine distance between the annotations of a worker $i$ and all annotations for the sentences they have worked on, weighted by the sentence and relation quality. It calculates how much a worker disagrees with the crowd on a sentence basis. Through the weighted average, sentences and relations with lower quality will have less of an impact on the final score.\n",
    "\n",
    "$$ WSA(i) = \\frac{\\sum_{s \\in sentences(i)} Wcos(WorkVec(i,s), SentVec(s) - WorkVec(i, s)) \\; SQS(s)}{\\sum_{s \\in sentences(i)} SQS(s)} .$$\n",
    "\n",
    "### Worker-Worker Agreement\n",
    "\n",
    "The worker-worker agreement $WWA(i)$ is the average cosine distance between the annotations of a worker $i$ and all other workers that have worked on the same sentences as worker $i$, weighted by the worker and relation qualities. The metric gives an indication as to whether there are consisently like-minded workers. This is useful for identifying communities of thought. Through the weighted average, workers and relations with lower quality will have less of an impact on the final score of the given worker.\n",
    "\n",
    "$$ WWA(i) = \\frac{ \\sum_{j \\in workers(s \\in sentences(i))} Wcos(WorkVec(i, s), WorkVec(j, s)) \\; WQS(j) \\; SQS(s) }{ \\sum_{j \\in workers(s \\in sentences(i))} WQS(j) \\; SQS(s) }, \\; i \\neq j .$$\n",
    "\n",
    "\n",
    "## Relation Quality Score (RQS)\n",
    "\n",
    "The relation quality score $RQS(r)$ calculates the agreement of selecting a relation $r$, over all the sentences it appears in. Therefore, it is only applicable to closed tasks, where the same relation set is used for all sentences/units. It is based on $P_r(i | j)$, the probability that if a worker $j$ annotates relation $r$ in a sentence, worker $i$ will also annotate it. $RQS(r)$ is the weighted average of $P_r(i | j)$ for all possible pairs of workers. Through the weighted average, sentences and relations with lower quality will have less of an impact on the final score of the relation.\n",
    "\n",
    "$$ RQS(r) = \\frac{ \\sum_{i,j} WQS(i) \\; WQS(j) \\; P_r(i | j) }{ \\sum_{i,j} WQS(i) \\; WQS(j) }, i \\neq j .$$\n",
    "\n",
    "$$ P_r(i | j) = \\frac{ \\sum_{s \\in sentences(i) \\cap sentences(j) } SQS(s) \\; WorkVec(i, s)(r) \\; WorkVec(j, s)(r) }{ \\sum_{s \\in sentences(i) \\cap sentences(j) } SQS(s) \\; WorkVec(j, s)(r) } . $$\n",
    "\n",
    "\n",
    "## Sentence-Relation Score (SRS)\n",
    "\n",
    "The sentence-relation score $SRS(s, r)$ calculates the likelihood that relation $r$ is expressed in sentence $s$. It is the ratio of the number of workers that picked relation $r$ over all workers that annotated the sentence, weighted by the worker quality.\n",
    "\n",
    "$$ SRS(s, r) = \\frac{ \\sum_{i \\in workers(s)} WorkVec(i,s)(r) \\; WQS(i) }{ \\sum_{i \\in workers(s)} WQS(i) }. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
